{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ca9f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27909472",
   "metadata": {},
   "source": [
    "# Problema 1: Portifolio de Investimentos\n",
    "\n",
    "## Dados:\n",
    " Série histórica de retornos de investimentos ao longo de 12 meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf834f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANÁLISE DE RISCO DE PORTFOLIO DE INVESTIMENTOS\n",
      "============================================================\n",
      "Retornos mensais (%) dos ativos:\n",
      "Mês      Ação A    Ação B    Ação C  Título D   Fundo E\n",
      "1           2.1      -1.5       3.2       0.8       1.2\n",
      "2           1.8       2.3      -0.5       0.9       1.1\n",
      "3          -0.5       1.8       2.1       0.7       0.9\n",
      "4           3.2      -2.1       1.8       0.8       1.3\n",
      "5           0.9       3.5      -1.2       0.6       1.0\n",
      "6           2.5       0.8       2.8       0.9       1.4\n",
      "7          -1.2       2.9       0.5       0.7       0.8\n",
      "8           1.6      -0.8       3.1       0.8       1.2\n",
      "9           2.8       1.5      -0.8       0.6       1.1\n",
      "10          0.3       2.7       1.9       0.9       1.3\n",
      "11          1.9      -1.3       2.4       0.7       0.9\n",
      "12          2.2       1.1       0.7       0.8       1.2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Análise de Risco de Portfolio de Investimentos\n",
    "\n",
    "Use normas e desvio padrão para analisar risco e retorno de investimentos.\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ANÁLISE DE RISCO DE PORTFOLIO DE INVESTIMENTOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Retornos mensais (%) de 5 ativos durante 12 meses\n",
    "ativos = ['Ação A', 'Ação B', 'Ação C', 'Título D', 'Fundo E']\n",
    "\n",
    "retornos = np.array([\n",
    "    [2.1, -1.5, 3.2, 0.8, 1.2],   # Mês 1\n",
    "    [1.8, 2.3, -0.5, 0.9, 1.1],   # Mês 2\n",
    "    [-0.5, 1.8, 2.1, 0.7, 0.9],   # Mês 3\n",
    "    [3.2, -2.1, 1.8, 0.8, 1.3],   # Mês 4\n",
    "    [0.9, 3.5, -1.2, 0.6, 1.0],   # Mês 5\n",
    "    [2.5, 0.8, 2.8, 0.9, 1.4],    # Mês 6\n",
    "    [-1.2, 2.9, 0.5, 0.7, 0.8],   # Mês 7\n",
    "    [1.6, -0.8, 3.1, 0.8, 1.2],   # Mês 8\n",
    "    [2.8, 1.5, -0.8, 0.6, 1.1],   # Mês 9\n",
    "    [0.3, 2.7, 1.9, 0.9, 1.3],    # Mês 10\n",
    "    [1.9, -1.3, 2.4, 0.7, 0.9],   # Mês 11\n",
    "    [2.2, 1.1, 0.7, 0.8, 1.2]     # Mês 12\n",
    "])\n",
    "\n",
    "print(\"Retornos mensais (%) dos ativos:\")\n",
    "print(f\"{'Mês':<5}\", end=\"\")\n",
    "for ativo in ativos:\n",
    "    print(f\"{ativo:>10}\", end=\"\")\n",
    "print()\n",
    "   \n",
    "for i in range(12):\n",
    "    print(f\"{i+1:<5}\", end=\"\")\n",
    "    for j in range(5):\n",
    "        print(f\"{retornos[i,j]:>10.1f}\", end=\"\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e2900ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a) Análise individual dos ativos:\n",
      "Ativo      Retorno Médio   Risco (Std)  Sharpe Ratio\n",
      "Ação A     1.47            1.283        1.143       \n",
      "Ação B     0.91            1.818        0.500       \n",
      "Ação C     1.33            1.485        0.898       \n",
      "Título D   0.77            0.103        7.462       \n",
      "Fundo E    1.12            0.177        6.303       \n"
     ]
    }
   ],
   "source": [
    "# a) Análise de retorno e risco individual\n",
    "print(f\"\\na) Análise individual dos ativos:\")\n",
    "print(f\"{'Ativo':<10} {'Retorno Médio':<15} {'Risco (Std)':<12} {'Sharpe Ratio':<12}\")\n",
    "                                            # o quanto se dis       # indica se compensa o risco do investimento\n",
    "                                            # tancia da media\n",
    "\n",
    "                            \n",
    "retornos_medios = np.mean (retornos, axis=0)    # axis = eixo = media de cada investimento\n",
    "\n",
    "riscos = np.std(retornos, axis=0)               # desvio padrão de cada investimento   -> risco\n",
    "\n",
    "sharpe_ratios = retornos_medios / riscos        # indica se compensa o investimento\n",
    "\n",
    "\n",
    "for i, ativo in enumerate(ativos):\n",
    "     print(f\"{ativo:<10} {retornos_medios[i]:<15.2f} {riscos[i]:<12.3f} {sharpe_ratios[i]:<12.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd7760",
   "metadata": {},
   "source": [
    "### b) Análise de correlação usando produto interno\n",
    "- Normalizar os retornos (centrar na média)\n",
    "    - retornos_centrados = retornos - retornos_medios\n",
    "\n",
    "- Exercício: Calcular a matriz de correlação usando produto interno\n",
    "    - $ C_{ij} = <v_i, v_j> / (||v_i||\\cdot ||v_j||)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94e2fe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retornos centrados:[[ 0.63333333 -2.40833333  1.86666667  0.03333333  0.08333333]\n",
      " [ 0.33333333  1.39166667 -1.83333333  0.13333333 -0.01666667]\n",
      " [-1.96666667  0.89166667  0.76666667 -0.06666667 -0.21666667]\n",
      " [ 1.73333333 -3.00833333  0.46666667  0.03333333  0.18333333]\n",
      " [-0.56666667  2.59166667 -2.53333333 -0.16666667 -0.11666667]\n",
      " [ 1.03333333 -0.10833333  1.46666667  0.13333333  0.28333333]\n",
      " [-2.66666667  1.99166667 -0.83333333 -0.06666667 -0.31666667]\n",
      " [ 0.13333333 -1.70833333  1.76666667  0.03333333  0.08333333]\n",
      " [ 1.33333333  0.59166667 -2.13333333 -0.16666667 -0.01666667]\n",
      " [-1.16666667  1.79166667  0.56666667  0.13333333  0.18333333]\n",
      " [ 0.43333333 -2.20833333  1.06666667 -0.06666667 -0.21666667]\n",
      " [ 0.73333333  0.19166667 -0.63333333  0.03333333  0.08333333]]\n",
      "\n",
      "\n",
      "[[ 1.         -0.61661665  0.07756007  0.18116709  0.63646006]\n",
      " [-0.61661665  1.         -0.67592713 -0.1769571  -0.32639199]\n",
      " [ 0.07756007 -0.67592713  1.          0.46623199  0.34324012]\n",
      " [ 0.18116709 -0.1769571   0.46623199  1.          0.67146234]\n",
      " [ 0.63646006 -0.32639199  0.34324012  0.67146234  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# b)   \n",
    "import numpy as np\n",
    "\n",
    "retornos = np.array([\n",
    "    [2.1, -1.5, 3.2, 0.8, 1.2],   # Mês 1\n",
    "    [1.8, 2.3, -0.5, 0.9, 1.1],   # Mês 2\n",
    "    [-0.5, 1.8, 2.1, 0.7, 0.9],   # Mês 3\n",
    "    [3.2, -2.1, 1.8, 0.8, 1.3],   # Mês 4\n",
    "    [0.9, 3.5, -1.2, 0.6, 1.0],   # Mês 5\n",
    "    [2.5, 0.8, 2.8, 0.9, 1.4],    # Mês 6\n",
    "    [-1.2, 2.9, 0.5, 0.7, 0.8],   # Mês 7\n",
    "    [1.6, -0.8, 3.1, 0.8, 1.2],   # Mês 8\n",
    "    [2.8, 1.5, -0.8, 0.6, 1.1],   # Mês 9\n",
    "    [0.3, 2.7, 1.9, 0.9, 1.3],    # Mês 10\n",
    "    [1.9, -1.3, 2.4, 0.7, 0.9],   # Mês 11\n",
    "    [2.2, 1.1, 0.7, 0.8, 1.2]     # Mês 12\n",
    "])\n",
    "\n",
    "retornos_medios = np.mean (retornos, axis=0)    # axis = eixo = media de cada investimento\n",
    "\n",
    "riscos = np.std(retornos, axis=0)               # desvio padrão de cada investimento   -> risco\n",
    "\n",
    "sharpe_ratios = retornos_medios / riscos        # indica se compensa o investimento\n",
    "\n",
    "# É aquele X barra -> X_barra = x - avg \n",
    "retornos_centrados = retornos - retornos_medios\n",
    "\n",
    "print (f\"Retornos centrados:{retornos_centrados}\\n\\n\")\n",
    "\n",
    "##################################################################\n",
    "\n",
    "C = np.zeros((5, 5))          # matriz de correlação\n",
    "\n",
    "for i in range(5):\n",
    "    vi = retornos_centrados[:,i]\n",
    "    for j in range(5):\n",
    "        vj = retornos_centrados[:,j] \n",
    "        C[i,j] = np.dot(vi, vj) / (np.linalg.norm(vi) * np.linalg.norm(vj))\n",
    "    \n",
    "print (C)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b35a91f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "c) Análise de diferentes portfolios:\n",
      "Portfolio    Retorno    Risco      Sharpe    \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# c) Análise de portfolios\n",
    "print(f\"\\nc) Análise de diferentes portfolios:\")\n",
    "\n",
    "# Portfolio 1: Igualmente distribuído\n",
    "pesos1 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "\n",
    "# Portfolio 2: Conservador (mais em títulos)\n",
    "pesos2 = np.array([0.1, 0.1, 0.1, 0.5, 0.2])\n",
    "\n",
    "# Portfolio 3: Agressivo (mais em ações)\n",
    "pesos3 = np.array([0.4, 0.3, 0.3, 0.0, 0.0])\n",
    "\n",
    "portfolios = [pesos1, pesos2, pesos3]\n",
    "nomes_portfolios = ['Equilibrado', 'Conservador', 'Agressivo']\n",
    "\n",
    "print(f\"{'Portfolio':<12} {'Retorno':<10} {'Risco':<10} {'Sharpe':<10}\")\n",
    "\n",
    "for i, (nome, pesos) in enumerate(zip(nomes_portfolios, portfolios)):\n",
    "    \n",
    "    # Retorno esperado do portfolio\n",
    "    retorno_medio_portifolio = np.dot(retornos_medios, pesos)\n",
    "\n",
    "    # Risco do portfolio (norma dos retornos ponderados centrados)\n",
    "    retorno_portfolio = np.dot(retornos, pesos)\n",
    "\n",
    "    risco_portfolio = np.std(retorno_portfolio)\n",
    "    \n",
    "    # Sharpe ratio\n",
    "    \n",
    "    sharpe_portfolio = retorno_medio_portifolio / risco_portfolio\n",
    "\n",
    "    # print(f\"{nome:<12} {retorno_portfolio:<10.2f} {risco_portfolio:<10.3f} {sharpe_portfolio:<10.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294cfd10",
   "metadata": {},
   "source": [
    "# Problema 2: Sistema de busca simples\n",
    "\n",
    "## Dados:\n",
    "- Lista de documentos ou páginas\n",
    "- texto de busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa4e844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Leitura de arquivos de texto:\n",
      "Arquivos encontrados: 5\n",
      "Primeiro arquivo lido:\n",
      "O esporte no Brasil é praticado em muitas modalidades e é organizado por confederações nacionais de ...\n"
     ]
    }
   ],
   "source": [
    "# Leitura dos arquivos de texto\n",
    "print(\"\\nLeitura de arquivos de texto:\")\n",
    "doc_dir = \"documentos\"\n",
    "\n",
    "# pega todos os arquivos de padrão .txt\n",
    "arquivos = glob.glob(f\"{doc_dir}/*.txt\")\n",
    "\n",
    "docs = []\n",
    "\n",
    "file_names = [arquivo.split('/')[-1].replace('.txt', '') for arquivo in arquivos]\n",
    "\n",
    "for arquivo in arquivos:\n",
    "    with open(arquivo, 'r', encoding='utf-8') as f:\n",
    "        docs.append(f.read())\n",
    "\n",
    "# Exemplo de arquivos lidos\n",
    "print(f\"Arquivos encontrados: {len(docs)}\")\n",
    "print(\"Primeiro arquivo lido:\")\n",
    "print(docs[0][:100] + \"...\")  # Exibe os primeiros 100 caracteres do primeiro arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e7fa67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de características (documentos x termos): (5, 699)\n",
      "Termos encontrados:\n",
      "['10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '1950' '1956' '1963'\n",
      " '20' '2007' '2012' '2016' '2017' '2020' '21']\n"
     ]
    }
   ],
   "source": [
    "# criação do vetor de características\n",
    "\n",
    "# palavras comuns a serem excluidas\n",
    "stopwords_pt = ['a', 'o', 'e', 'de', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'foi', 'ao', 'ele', 'das', 'tem', 'à', 'seu', 'sua', 'ou', 'ser', 'quando', 'muito', 'há', 'nos', 'já', 'está', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'era', 'depois', 'sem', 'mesmo', 'aos', 'ter', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'estão', 'você', 'tinha', 'foram', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'têm', 'numa', 'pelos', 'elas', 'havia', 'seja', 'qual', 'será', 'nós', 'tenho', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n",
    "\n",
    "# retirando as palavras\n",
    "vectorizer = CountVectorizer(stop_words=stopwords_pt)\n",
    "\n",
    "# fit - aprende o vocabulário || transform - transforma os dados - conte as palavras\n",
    "X = vectorizer.fit_transform(docs)\n",
    "\n",
    "# x é uma matriz esparsa com as palavras\n",
    "\n",
    "# Exibe o tamanho da matriz de características\n",
    "print(f\"\\nMatriz de características (documentos x termos): {X.shape}\")\n",
    "print(\"Termos encontrados:\")\n",
    "print(vectorizer.get_feature_names_out()[:20])  # Exibe os primeiros 20 termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f14ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exemplo de busca: Buscar documento com maior semelhança de coseno\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m texto_busca = \u001b[33m\"\u001b[39m\u001b[33mcomida mais popular no Brasil\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# usa o transform - transforma em um vetor de busca\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m X_busca = \u001b[43mvectorizer\u001b[49m.transform([texto_busca])\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# similaridade de cos -> ou seja, cosseno entre dois vetores -> retorna x posições (cada palavra da string texto_busca)\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# dois vetores que \"apontam\" pra mesma direção -> proximo de 1 -> próximos\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# dois vetores que \"apontam\" pra direção opostas -> proximo de 0 -> não próximos\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# proximidade com correlação\u001b[39;00m\n\u001b[32m     14\u001b[39m similaridades = np.linalg.norm(X.toarray() - X_busca.toarray(), axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "# exemplo de busca: Buscar documento com maior semelhança de coseno\n",
    "print(\"\\nExemplo de busca: Buscar documento com maior semelhança de coseno\")\n",
    "\n",
    "# string procurada\n",
    "texto_busca = \"comida mais popular no Brasil\"\n",
    "\n",
    "# usa o transform - transforma em um vetor de busca\n",
    "X_busca = vectorizer.transform([texto_busca])\n",
    "\n",
    "# similaridade de cos -> ou seja, cosseno entre dois vetores -> retorna x posições (cada palavra da string texto_busca)\n",
    "# dois vetores que \"apontam\" pra mesma direção -> proximo de 1 -> próximos\n",
    "# dois vetores que \"apontam\" pra direção opostas -> proximo de 0 -> não próximos\n",
    "# proximidade com correlação\n",
    "\n",
    "# axis = 1 -> calcula a norma só das colunas (0 - linha\n",
    "#                                             1 - coluna)\n",
    "# axis indica sobre qual eixo será operado -> axis = 0, cada linha é um vetor\n",
    "similaridades = np.linalg.norm(X.toarray() - X_busca.toarray(), axis=1)\n",
    "\n",
    "#\n",
    "indice_mais_similar = np.argmax(similaridades)\n",
    "\n",
    "print(f\"Documento mais similar encontrado: {file_names[indice_mais_similar]}\")\n",
    "print(f\"Conteúdo do documento mais similar:\\n{docs[indice_mais_similar][:200]}...\")  # Exibe os primeiros 200 caracteres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139dd577",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'vectorizer' from 'sklearn.feature_extraction.text' (c:\\Users\\Cauan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vectorizer\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# exemplo de busca: Buscar documento com maior semelhança de coseno\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mExemplo de busca: Buscar documento com maior semelhança de coseno\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'vectorizer' from 'sklearn.feature_extraction.text' (c:\\Users\\Cauan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py)"
     ]
    }
   ],
   "source": [
    "# Exercicio: mude o critério de busca para encontrar documentos que estejam mais proximos pela distancia euclidiana\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# exemplo de busca: Buscar documento com maior semelhança de coseno\n",
    "print(\"\\nExemplo de busca: Buscar documento com maior semelhança de coseno\")\n",
    "\n",
    "# string procurada\n",
    "texto_busca = \"comida mais popular no Brasil\"\n",
    "\n",
    "# usa o transform - transforma em um vetor de busca\n",
    "X_busca = vectorizer.transform([texto_busca])\n",
    "\n",
    "\n",
    "# palavras comuns a serem excluidas\n",
    "stopwords_pt = ['a', 'o', 'e', 'de', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'foi', 'ao', 'ele', 'das', 'tem', 'à', 'seu', 'sua', 'ou', 'ser', 'quando', 'muito', 'há', 'nos', 'já', 'está', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'era', 'depois', 'sem', 'mesmo', 'aos', 'ter', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'estão', 'você', 'tinha', 'foram', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'têm', 'numa', 'pelos', 'elas', 'havia', 'seja', 'qual', 'será', 'nós', 'tenho', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n",
    "\n",
    "# retirando as palavras\n",
    "vectorizer = CountVectorizer(stop_words=stopwords_pt)\n",
    "\n",
    "# fit - aprende o vocabulário || transform - transforma os dados - conte as palavras\n",
    "X = vectorizer.fit_transform(docs)\n",
    "\n",
    "\n",
    "similaridades = np.linalg.norm(X.toarray() - X_busca.toarray(), axis=1)\n",
    "\n",
    "#\n",
    "indice_mais_similar = np.argmax(similaridades)\n",
    "\n",
    "print(f\"Documento mais similar encontrado: {file_names[indice_mais_similar]}\")\n",
    "print(f\"Conteúdo do documento mais similar:\\n{docs[indice_mais_similar][:200]}...\")  # Exibe os primeiros 200 caracteres\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
